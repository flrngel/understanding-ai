# Understanding Artificial Intelligence

My works for understanding ai papers, ai projects, etc.

## Implemented Papers

- [Attention Is All You Need](https://github.com/flrngel/Transformer-tensorflow)
- [A Structured Self-Attentive Sentence Embedding](https://github.com/flrngel/Self-Attentive-tensorflow)
- [Training RNNs as Fast as CNNs (Single Recurrent Unit)](https://github.com/flrngel/sru-tensorflow)
- [TagSpace: Semantic Embeddings from Hashtags](https://github.com/flrngel/TagSpace-tensorflow)

## Personal Research

- [Character based Temporal Convolutional Networks + Attention Layer](https://github.com/flrngel/TCN-with-attention)

## Notes on papers

Note on papers using [Github Issues](https://github.com/flrngel/understanding-ai/issues?utf8=%E2%9C%93&q=is%3Aissue+is%3Aopen+sort%3Acreated-desc) starting from `January 29, 2018`
(inspired by [kweonwooj/papers](https://github.com/kweonwooj/papers))

For convenience of searching the notes on paper

**Paper List**

- [Subspace match probably does not accurately assess the similarity of learned representations](https://github.com/flrngel/understanding-ai/issues/25)
- [Representation Learning with Contrastive Predictive Coding](https://github.com/flrngel/understanding-ai/issues/24)
- [Neural Discrete Representation Learning](https://github.com/flrngel/understanding-ai/issues/23)
- [A Quantum Many-body Wave Function Inspired Language Modeling Approach](https://github.com/flrngel/understanding-ai/issues/22)
- [Self Imitation Learning](https://github.com/flrngel/understanding-ai/issues/21)
- [Local sparsity control for Naive Bayes with extreme misclassiication costs](https://github.com/flrngel/understanding-ai/issues/20)
- [What you get is what you see: A visual markup decompiler](https://github.com/flrngel/understanding-ai/issues/19)
- [A Simple Method for Commonsense Reasoning](https://github.com/flrngel/understanding-ai/issues/18)
- [Relational recurrent neural networks](https://github.com/flrngel/understanding-ai/issues/17)
- [Language Modeling with Gated Convolutional Networks](https://github.com/flrngel/understanding-ai/issues/16)
- [A Hybrid Convolutional Variational Autoencoder for Text Generation](https://github.com/flrngel/understanding-ai/issues/15)
- [Asynchronous Methods for Deep Reinforcement Learning](https://github.com/flrngel/understanding-ai/issues/14)
- [Dual Learning for Machine Translation](https://github.com/flrngel/understanding-ai/issues/13)
- [An Empirical Evaluation of generic Convolutional and Recurrent Networks for Sequence Modeling](https://github.com/flrngel/understanding-ai/issues/12)
- [Neural Machine Translation in Linear Time](https://github.com/flrngel/understanding-ai/issues/11)
- [Learning to Generate Reviews and Discovering Sentiment](https://github.com/flrngel/understanding-ai/issues/10)
- [Zero-Shot Question Generation from Knowledge Graphs for Unseen Predicates and Entity Types](https://github.com/flrngel/understanding-ai/issues/9)
- [Neural Voice Cloning with a Few Samples](https://github.com/flrngel/understanding-ai/issues/8)
- [Diversity Is All You Need: Learning Skills without a Reward Function](https://github.com/flrngel/understanding-ai/issues/7)
- [Non-Autoregressive Neural Machine Translation](https://github.com/flrngel/understanding-ai/issues/6)
- [Generating Wikipedia By Summarizing Long Sequences](https://github.com/flrngel/understanding-ai/issues/5)
- [Zero-Shot Super-Resolution using Deep Internal Learning](https://github.com/flrngel/understanding-ai/issues/4)
- [Convolution Sequence to Sequence Learning](https://github.com/flrngel/understanding-ai/issues/3)
- [Bi-Directional Block Self-Attention for fast and memory-efficient sequence modeling](https://github.com/flrngel/understanding-ai/issues/2)
- [Convolution Sequence to Sequence Learning](https://github.com/flrngel/understanding-ai/issues/1)
